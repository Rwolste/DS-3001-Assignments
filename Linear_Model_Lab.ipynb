{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1zPBdbZfkaLWVL5Dh1kSg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rwolste/DS-3001-Assignments/blob/main/Linear_Model_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# === 1. Load the dataset ===\n",
        "df = pd.read_csv(\"cars_hw.csv\")\n",
        "\n",
        "# === 2. Drop unnecessary index column ===\n",
        "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
        "\n",
        "# === 3. One-hot encode categorical variables ===\n",
        "categorical_cols = ['Make', 'Color', 'Body_Type', 'No_of_Owners',\n",
        "                    'Fuel_Type', 'Transmission', 'Transmission_Type']\n",
        "cars_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# === 4. Define features and target ===\n",
        "X = cars_encoded.drop(columns=[\"Price\"])\n",
        "y = cars_encoded[\"Price\"]\n",
        "\n",
        "# === 5. Train-test split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# === 6. Create transformation pipeline for selected features ===\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('log_mileage', FunctionTransformer(lambda x: np.log1p(x))),  # log(1 + x)\n",
        "    ('poly', PolynomialFeatures(degree=2, include_bias=False))    # adds interactions and squares\n",
        "])\n",
        "\n",
        "# === 7. ColumnTransformer to apply only on selected columns ===\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('numeric', numeric_transformer, ['Mileage_Run', 'Make_Year'])\n",
        "], remainder='passthrough')  # keep all other columns unchanged\n",
        "\n",
        "# === 8. Full pipeline: preprocess + linear regression ===\n",
        "complex_model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# === 9. Fit model ===\n",
        "complex_model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# === 10. Predict on train and test sets ===\n",
        "y_train_pred = complex_model_pipeline.predict(X_train)\n",
        "y_test_pred = complex_model_pipeline.predict(X_test)\n",
        "\n",
        "# === 11. Evaluate performance ===\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# === 12. Print results ===\n",
        "print(\"Model Performance:\")\n",
        "print(f\"Train RMSE: â‚¹{train_rmse:,.0f}\")\n",
        "print(f\"Test RMSE: â‚¹{test_rmse:,.0f}\")\n",
        "print(f\"Train RÂ²: {train_r2:.3f}\")\n",
        "print(f\"Test RÂ²: {test_r2:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3qebeCpttyb",
        "outputId": "930e8381-a9bf-40a0-9de6-679c94406216"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Model Performance:\n",
            "Train RMSE: â‚¹140,383\n",
            "Test RMSE: â‚¹142,266\n",
            "Train RÂ²: 0.859\n",
            "Test RÂ²: 0.824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best model is the Complex model since it has a slightly lower RSME and a higher R^2. We saw some non linearity in the mileage variable. The complex model outperforms the simpler one, mainly due to handling non-linear effects and interactions. But the improvement is incremental, showing that while complexity can help, it's important to avoid going overboard unless justified by patterns in the data. We cleaned and explored the data, transformed categorical variables, and split it for training and testing. A simple linear model performed well, but a complex model with log and interaction terms did better. We learned that careful feature engineering improves performance and that added complexity can help without causing overfitting."
      ],
      "metadata": {
        "id": "EulvnedkuA6I"
      }
    }
  ]
}